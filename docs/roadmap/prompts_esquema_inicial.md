generar la configuraciÃ³n inicial de base de datos, modelos, migraciones y repositorios del proyecto.

# ðŸ“‹ Prompts for GitHub Copilot â€” Initial Schema and Migrations

This document collects **suggested prompts for GitHub Copilot in VS Code**, with the goal of generating the initial database configuration, models, migrations, and repositories for the project.

---

## Prompt 1 â€” DB Config and Session (engine, SessionLocal, Base)

```text
You are GitHub Copilot. Create a Python module `backend/app/db.py` that configures SQLAlchemy for a FastAPI project using Postgres.

Requirements:
- PEP8, internal variables/functions in camelCase.
- Read DATABASE_URL from environment (raise clear error if missing).
- Create `engine` with sensible pool settings for a small VPS:
  - pool_pre_ping=True, pool_size=5, max_overflow=5, pool_recycle=1800
- Create `SessionLocal = sessionmaker(...)` and `Base = declarative_base()`.
- Implement `getDb()` FastAPI dependency that yields a session and ensures close in a finally block.
- Add docstrings explaining each public symbol.
- Add typing annotations and a minimal logger for connection errors.
```

---

## Prompt 2 â€” SQLAlchemy Models (users, licenses, jobs, file_artifacts)

```text
You are GitHub Copilot. Implement SQLAlchemy models in `backend/app/models.py` for a transcription service.

Context:
- Using Postgres only. Prefer `JSONB` via `sqlalchemy.dialects.postgresql`.
- Import `Base` from app.db.

Models to create (with PEP8, camelCase internal attrs, docstrings):
1) User: id (UUID string), email unique/indexed, passwordHash, role, createdAt.
2) License: key PK, assignedToUserId (FK), plan, features JSONB, validFrom, validUntil, isRevoked, createdAt.
3) Job: id PK, ownerUserId FK, status, modelName, mode, language, audioDurationMs, processingTimeMs, resultJsonPath, transcriptTxtPath, createdAt, updatedAt, errorMessage.
4) FileArtifact: id PK, jobId FK, type, path, sizeBytes, createdAt, Unique(jobId,type).

Notes:
- Use `JSONB`.
- Relationships optional.
- Add __repr__ methods for debugging.
```

---

## Prompt 3 â€” Initialize Alembic and Link Metadata

```text
You are GitHub Copilot. Configure Alembic for this FastAPI project.

Tasks:
- Create `alembic.ini` with standard settings.
- Create `backend/alembic/` structure with `env.py`, `script.py.mako`, and `versions/`.
- In `env.py`:
  - Load DATABASE_URL from environment.
  - Import `Base` from `app.db` and set `target_metadata = Base.metadata`.
  - Support offline and online modes.
  - Enable compare_type=True and compare_server_default=True for autogenerate.
- Add a comment explaining how to run migrations.
```

---

## Prompt 4 â€” Initial Autogenerated Migration

```text
You are GitHub Copilot. Generate the initial Alembic migration file to create the schema defined in `backend/app/models.py`.

Requirements:
- Name the migration "init schema".
- Create tables: users, licenses, jobs, file_artifacts.
- Include PKs, FKs with ondelete, indices, composite index on jobs, unique (jobId,type).
- Use Postgres JSONB.
- Provide downgrade() that drops tables in dependency order.
- Add concise docstring.
```

---

## Prompt 5 â€” Repositories/services CRUD

```text
You are GitHub Copilot. Create repository modules under `backend/app/repos/`:
1) users_repo.py: create_user, get_user_by_email, get_user_by_id.
2) licenses_repo.py: upsert_license, get_license_by_key, assign_license_to_user.
3) jobs_repo.py: create_job, get_job_by_id, list_jobs_by_user, set_job_status.
4) artifacts_repo.py: add_artifact, list_artifacts_by_job, get_artifact_by_type.

Requirements:
- Use SQLAlchemy sessions from get_db().
- PEP8 (snake_case), type hints.
- Raise ValueError for invalid input, return objects or None.
- Keep functions small and documented.
```

---

## Prompt 6 â€” Pydantic Schemas and Test Endpoints (PEP8)

```text
Implement Pydantic schemas in `backend/app/schemas.py` and a router in
`backend/app/routers/jobs.py`.

Requirements (PEP8, snake_case, type hints, docstrings):
- Schemas: `JobCreateIn`, `JobOut`.
  - Include typical fields (e.g., model_name, language, status: Literal["queued","processing","done","failed"], created_at, etc.).
- Router: prefix `/api/transcriptions`.
  - `POST /` â†’ create job, returns `201 Created`, `response_model=JobOut`, set `Location` header to `/{id}`.
  - `GET /` â†’ list jobs by current user, supports `status` (optional), `limit` (int=50), `offset` (int=0),
    returns `list[JobOut]`.
  - `GET /{id}` â†’ job detail, returns `JobOut`.
- Use FastAPI dependencies with `Depends(get_db)`; create handlers in snake_case.
- Minimal error handling:
  - Return `HTTPException(status_code=404)` if job not found.
  - Map `ValueError` to `HTTPException(status_code=400)`.
- Imports to prefer: `from fastapi import APIRouter, Depends, HTTPException, status`.
- Keep functions small, with clear docstrings and type annotations.
```

---

## Prompt 7 â€” Health checks (API, Redis, DB)

```text
Create a health router at `backend/app/routers/health.py`.

Requirements:
- Use FastAPI (PEP8, snake_case, type hints, docstrings).
- Endpoints:
  1) GET `/api/health` (liveness): returns service up without touching DB/Redis.
  2) GET `/api/ready` (readiness): checks DB (SELECT 1) and optional Redis PING with timeouts.
- Use dependencies: `Depends(get_db)` for DB; accept an optional `redis_client` provider (can be None).
- Return a typed schema `HealthOut` with fields:
  - `db_ok: bool`
  - `redis_ok: bool | None` (None if Redis not configured)
  - `version: str` (read from `GIT_SHA` or `APP_VERSION` env, default `"dev"`)
  - `time: int` (epoch seconds)
- Behavior:
  - If DB check fails, respond `503 Service Unavailable`.
  - If Redis is configured and ping fails, respond `503`, else keep it `200`.
  - Liveness (`/api/health`) always responds `200` with `db_ok=None`, `redis_ok=None`.
- Implementation notes:
  - Use `from sqlalchemy import text` and `session.execute(text("SELECT 1"))`.
  - For Redis, wrap ping in `try/except` with a short timeout (e.g., 0.2s).
  - Prefer `from fastapi import APIRouter, Depends, HTTPException, status`.
  - Keep functions small, add docstrings, and type annotations.
```

---

## Prompt 8 â€” Seed Demo Script

```text
Create `backend/scripts/seed_demo.py`.

Goals:
- Insert a demo admin and a demo user (idempotent: don't duplicate if rerun).
- Create 3 jobs for the demo user with different statuses and attach FileArtifact rows.
- Use `get_db()` from `backend/app/db.py` to obtain a SQLAlchemy session.
- Print a concise summary at the end.

Constraints & conventions (match project style):
- PEP8 (snake_case), type hints, module-level logger, clear docstrings.
- Use UTC timestamps: `datetime.now(timezone.utc)`.
- Assume models are in `backend/app/models.py` with snake_case attributes:
  - User(email, password_hash, role, created_at)
  - Job(owner_user_id, status, model_name, language, created_at, updated_at,
        audio_duration_ms, processing_time_ms, result_json_path, transcript_txt_path, error_message)
  - FileArtifact(job_id, type, path, size_bytes, created_at)
- Valid job statuses: "queued", "processing", "done", "failed".
- Make the script safe to import and runnable: `if __name__ == "__main__": main()`.

Behavior:
- Idempotency:
  - Upsert users by `email` ("admin@example.com", "user@example.com").
  - Only create demo jobs if none exist for the demo user (or behind a `--force` flag).
- CLI:
  - `--force`  â†’ recreate demo jobs (delete existing demo jobs/artifacts for the demo user first).
  - `--reset`  â†’ delete ALL data from jobs and file_artifacts (and demo users' jobs), then reseed.
- Transactions:
  - Use a single session context; commit on success, rollback on exception.
  - Catch `IntegrityError` and re-raise with a helpful message.
- Demo data:
  - Jobs: create 3 jobs with statuses: queued, processing, done.
  - For the "done" job, add two FileArtifact rows: `{"type": "result_json", "path": "/data/demo/result.json"}`,
    `{"type": "transcript_txt", "path": "/data/demo/transcript.txt"}` with small dummy `size_bytes`.
- Output:
  - Print a one-line summary: counts of users, jobs, artifacts created/left.
  - Log debug lines with created IDs.

Imports to prefer:
- `from backend.app.db import get_db`
- `from backend.app import models`
- `from sqlalchemy.exc import IntegrityError`
- `from sqlalchemy import delete, select`
- stdlib: `argparse`, `logging`, `datetime`, `uuid`

Quality:
- Small functions: `get_or_create_user(...)`, `ensure_demo_jobs(...)`, `wipe_demo_jobs(...)`.
- Type annotations everywhere. Keep functions pure where possible.
- Avoid hard exits inside helpers; raise exceptions and handle in `main()`.
```

---

## Prompt 9 â€” Makefile targets Alembic/seed

```text
You are GitHub Copilot. Add Make targets:
- db-rev: alembic revision --autogenerate -m "$(m)"
- db-up: alembic upgrade head
- db-dn: alembic downgrade -1
- db-seed: python -m backend.scripts.seed_demo

Assumptions: Alembic under backend/alembic.
```
